= BAR :: Behaviour ARchive image:https://maven-badges.herokuapp.com/maven-central/com.github.t1/wunderbar.junit/badge.svg[link=https://search.maven.org/artifact/com.github.t1/wunderbar.junit] image:https://github.com/t1/wunderbar/actions/workflows/maven.yml/badge.svg[link=https://github.com/t1/wunderbar/actions/workflows/maven.yml]

Code-first, low ceremony https://martinfowler.com/articles/consumerDrivenContracts.html[Consumer Driven Contracts] test tool for Java natives.

Let's pick that apart:

"code-first": there's a lot of debate about designing APIs schema-first (a.k.a. api-first) vs. code-first.
I absolutely agree that (not only for public APIs) it's very important to design APIs in a consistent and easily approachable way.
I even think that it's actually more important to capture the real use-cases of real consumers of an API.
It's just way too easy to design something that looks good as a schema but is clumsy to use in practice.
And by lowering the bar to specify the (changes to an) API as much as possible, consumers are invited to help evolve the API in a pragmatic way that is easy to use.

"low ceremony": use it just like you'd use https://site.mockito.org[Mockito] to test your client code.
Easily scale that from Unit to Integration Test, so you also cover all the serialization and http request/response involved.
Supports REST (via https://github.com/eclipse/microprofile-rest-client[MicroProfile REST Client]) and https://graphql.org[GraphQL] (via https://github.com/smallrye/smallrye-graphql/tree/main/client/api[SmallRye GraphQL Client]).
This helps clients to test their own code.

As a side effect, WunderBar records the expected http interactions into a Behavior ARchive file, ready to be handed over to the API provider to verify compliance with the client requirements.
For the details see below.

Just to make it clear: just because the consumer drives the API contract doesn't mean that the provider is expected to comply blindly.
It's only a starting point for the contract negotiation.
The provider has to evolve a domain model that is consistent over all consumers: the BAR files are not a replacement for talking; they just bring it to the precision that the machines foolishly insist on; and a long-term test suite of acceptance tests.
Starting from the API Consumer perspective is actually just a very natural way of defining an API: from the real requirements.

== 2 Minute API Consumer Intro

Say you're developing an Order system that uses data from a Product service, i.e. it _consumes_ an API.
You probably have a `ProductsGateway` or `ProductsResolver` class that uses a `ProductsClient` interface with annotations from https://github.com/eclipse/microprofile-rest-client[MP Rest Client] or https://github.com/smallrye/smallrye-graphql/tree/main/client/api[SmallRye GraphQL Client] that you unit-test with Mockito:

[source,java]
----
@RegisterRestClient @Path("/products")
public interface ProductsClient {
    @GET @Path("/{id}")
    Product product(@PathParam("id") String id);
}

// or alternatively

@GraphQLClientApi
public interface ProductsClient {
    Product product(String id);
}

// test

@ExtendWith(MockitoExtension.class)
class ProductsGatewayMockitoTest {
    @Mock ProductsClient products;
    @InjectMocks ProductsGateway gateway;

    @Test void shouldGetProduct() {
        given(products.product(PRODUCT_ID)).willReturn(PRODUCT);

        var response = gateway.product(ORDER_ITEM);

        then(response).usingRecursiveComparison().isEqualTo(PRODUCT);
    }
}
----

Instead of using the Mockito extension with its annotations and the static `given` method import, you can simply use those from WunderBar.
They are more limited than Mockito, but have the same style, same behavior, just different logs:

[source,java]
----
@WunderBarApiConsumer
class ProductsGatewayTest {
    @Service ProductsClient products;
    @SystemUnderTest ProductsGateway gateway;

    @Test void shouldGetProduct() {
        given(products.product(PRODUCT_ID)).returns(PRODUCT);

        var response = gateway.product(ITEM);

        then(response).usingRecursiveComparison().isEqualTo(PRODUCT);
    }
}
----

Note that you can also use the Mockito syntax `given(...).willReturn(...)`, but using `returns` makes sure you don't accidentally use the `given` from Mockito.

To make things interesting, you can change the `@WunderBarApiConsumer` annotation to `@WunderBarApiConsumer(level = INTEGRATION)` (or simply change the test name to end with `IT`, short for Integration Test): WunderBar now starts a mock server exposing the behavior you just stubbed, i.e. it will reply to your real http request with the proper product.
No code changes needed, and now it fully tests your REST or GraphQL client annotations and (de)serialization of your POJOs.

This is nice, but as a welcome side effect, it _records_ the requests and responses you need for your code to work, and saves it in a `wunder.bar` file (Behavior ARchive).
Give this file to your API provider, so they can check if their service complies to your requirements.
You can even deploy this file, together with your other maven artefacts, e.g. by using the `attach-artifact` goal of the `build-helper-maven-plugin`; for an example, look at the pom in the https://github.com/t1/wunderbar/blob/trunk/demo/order/pom.xml[`demo/order`] submodule.

== 2 Minute API Provider Intro

When you implement an API (i.e. you provide it), you can load a suite of tests that has been stored in a `wunder.bar` file, and run them against your service:

[source,java]
----
@WunderBarApiProvider(baseUri = "http://localhost:8080")
class ConsumerDrivenAT {
    @TestFactory DynamicNode orderTests() {
        return findTestsIn("wunder.bar");
    }
}
----

There are several ways to load `bar` files; e.g., you can also load them from maven coordinates.
See the public methods in the https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/WunderBarTestFinder.java[`WunderBarTestFinder`] class for details.

The requirements will be more specific than your service, but that's a good thing: thankfully, your service will be lenient in some cases; e.g. it accepts different content type encodings.
In this way, a client can change some details of its technical requirements, e.g. by requesting a different encoding or even content type; as long as your service supports it, the tests continue to pass.
And if it doesn't support it, it will show up as soon as the new version of the bar file runs.

If the test data in your service is static and matches precisely the expectations of your clients/consumers, that's it!
But to be honest, managing test data is generally a nastily complex issue, and WunderBar can help, but can't make it go away completely.

=== Managing Test Data

The expected data in a `bar` generated by a https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/consumer/Level.java#L51[system test] matches the data in the service at the time it ran.
So the actual test data often changes or is even deleted for various reasons: some data simply times out, other data is changed by manual as well as automated tests, etc.
Coordinating this is difficult and requires communication between different teams, resulting in a high effort and the tests being brittle: they sporadically break without exposing an actual bug anywhere but in this coordination between people.
OTOH, when the API consumers run https://github.com/t1/wunderbar/blob/2d939132a56337a86cb87718acbbc0f02cbd52ae/junit/src/main/java/com/github/t1/wunderbar/junit/consumer/Level.java#L34[integration tests], they touch only a mocked system, so the data they expect doesn't exist in your real (test) system.
In both cases, the consumers may even generate the test data randomly (which has a lot of benefits, BTW).

This all means that you'll have to set up (and maybe clean up) data in your service to match the consumers' requirements, i.e. mostly putting the expected response into your system.
You can do so by using some mutating APIs of your service, or by storing and deleting the data directly into your database, or by defining an extra test backdoor API for your service:
either way, you'll need do this kind of test setup before every test in the BAR (and maybe some cleanup thereafter).
Just define a method, annotated as https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/BeforeInteraction.java[`@BeforeInteraction`] / https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/AfterInteraction.java[`@AfterInteraction`] footnote:[JUnit invokes the standard JUnit `@Before/AfterEach` methods only once for every test method, not for every test in a `DynamicNode`. WunderBar also calls methods annotated as https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/BeforeDynamicTest.java[`@BeforeDynamicTest`] / https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/AfterDynamicTest.java[`@AfterDynamicTest`]; the difference is that, in some cases, there can be several subsequent interactions in one dynamic test.], taking a single https://github.com/t1/wunderbar/blob/trunk/lib/src/main/java/com/github/t1/wunderbar/junit/http/HttpInteraction.java[`HttpInteraction`] as a parameter, which basically just bundles an https://github.com/t1/wunderbar/blob/trunk/lib/src/main/java/com/github/t1/wunderbar/junit/http/HttpRequest.java[`HttpRequest`] and an https://github.com/t1/wunderbar/blob/trunk/lib/src/main/java/com/github/t1/wunderbar/junit/http/HttpResponse.java[`HttpResponse`].

In addition to storing the data, you can also return an `HttpInteraction`, `HttpRequest`, or `HttpResponse` from your method to modify the interaction, e.g. replace the dummy credentials (xref:credentials[see below]) with real credentials, or replace the originally expected id with the id generated by a database sequence for this test run.
There are a bunch of convenient methods in the https://github.com/t1/wunderbar/blob/trunk/lib/src/main/java/com/github/t1/wunderbar/junit/http/HttpRequest.java[`HttpRequest`] and https://github.com/t1/wunderbar/blob/trunk/lib/src/main/java/com/github/t1/wunderbar/junit/http/HttpResponse.java[`HttpResponse`] classes to help here.

Writing your acceptance tests in this way makes testing more robust, as you don't have to agree with the consumers of your APIs on any volatile and intransparent assumptions about the test data, e.g. what ids or data fields result in what behavior.
For a fully running example, see the demo https://github.com/t1/wunderbar/blob/main/demo/product/src/test/java/test/acceptance/ConsumerDrivenAT.java[ConsumerDrivenAT].

[#credentials]
== Credentials

`bar` files never contain the secrets of a real `Authorization` header footnote:[They used to say that the username was a secret, too, but when you use good passwords (i.e. really random and really long), this is not necessary anymore, but it makes life so much easier to see the username].
They could contain random values for integration tests, without adding any benefit; for system tests, the interactions would even contain real credentials.
So WunderBar only writes dummy values instead.

For a GraphQL client, you can use the `@AuthorizationHeader` annotation to read the configuration from an MP Config property; but you don't have to actually provide those for an integration test, as they won't be written anyway; a dummy value will be written instead.
OTOH, a `@Header(name = "Authorization")` works normally (but won't be written either).

On the API provider side, the acceptance test has to replace this value with real credentials, e.g. by returning a modified `HttpRequest` in a `@BeforeInteraction` method.

== Full Dependency Injection

Using the `@SystemUnderTest` annotation performs only a very limited form of dependency injection.
For more complex dependency requirements, it may be appropriate to use, e.g., https://github.com/weld/weld-junit/blob/master/junit5/README.md[`weld-junit5`] as a fully blown CDI testing environment.
To do so, do the following steps:

1. add a `test` scope dependency on `org.jboss.weld:weld-junit5`,
2. annotate your test class with `@EnableWeld` _after_ (this is important) the `@WunderBarApiConsumer` annotation,
3. instead of `@SystemUnderTest`, use the CDI `@Inject` annotation, and
4. build a `WeldInitiator` with your classes, and for the services, add a mock bean with a _delayed_ `create` producer of the WunderBar-mocked service field.

This sums up like this:

[source,java]
----
@WunderBarApiConsumer
@EnableWeld
class ProductsResolverWeldIT {
    @Service Products products;
    @Inject ProductsResolver resolver;

    @WeldSetup
    WeldInitiator weld = WeldInitiator.from(ProductsResolver.class, Products.class)
        .addBeans(MockBean.builder().types(Products.class).create(ctx -> products).build())
        .build();
}
----

In this way, WunderBar produces the service proxy, and Weld can inject it into your system under test.
For a complete example, take a look at https://github.com/t1/wunderbar/blob/main/demo/order/src/test/java/test/graphql/ProductsResolverWeldIT.java[`ProductsResolverWeldIT`].

== Documentation

The full documentation is in the JavaDoc, mainly in the https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/consumer/WunderBarApiConsumer.java[`@WunderBarApiConsumer`] annotation, the https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/consumer/Level.java[`Level`] enum and the https://github.com/t1/wunderbar/blob/main/junit/src/main/java/com/github/t1/wunderbar/junit/consumer/WunderbarExpectationBuilder.java[`WunderbarExpectationBuilder`] for the API consumer (client) side and in the https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/WunderBarApiProvider.java[`@WunderBarApiProvider`] annotation and the https://github.com/t1/wunderbar/blob/trunk/junit/src/main/java/com/github/t1/wunderbar/junit/provider/WunderBarTestFinder.java[`WunderBarTestFinder`] for the API provider (server) side.

The `demo` module contains two example projects: `order` consumes an API that the `product` service provides.
Both in REST and GraphQL and on all test levels.

If you have further questions, don't hesitate to ask questions on Stack Overflow tagged with https://stackoverflow.com/questions/tagged/wunderbar[wunderbar].
Contributions are also very welcome, of course: start discussions, open issues, add comments, share it online or offline, and if you like it, give it a star on GitHub, please 😁
